{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Q4vVUgxxDJD0",
      "metadata": {
        "id": "Q4vVUgxxDJD0"
      },
      "source": [
        "# <font color = green>**HW1 - 15 Points** </font>\n",
        "- **You have to submit two files for this part of the HW**\n",
        "  >(1) ipynb (colab notebook) and<br>\n",
        "  >(2) pdf file (pdf version of the colab file).**\n",
        "- **Files should be named as follows**:\n",
        ">FirstName_LastName_HW_1**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ard9xn_RfnWc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ard9xn_RfnWc",
        "outputId": "9c928801-c03b-448c-ed08-81cab0d78932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67ee335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a67ee335",
        "outputId": "40551848-afcd-4530-fd8d-c43e2a53eaa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "IsWkg1CufBwg",
      "metadata": {
        "id": "IsWkg1CufBwg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Voz6l5RUZRh",
      "metadata": {
        "id": "2Voz6l5RUZRh"
      },
      "source": [
        "# <font color = green>**Q1 : Create Tensor (1/2 Point)**\n",
        " Create a torch Tensor of shape (5, 3) which is filled with zeros. Modify the tensor to set element (0, 2) to 10 and element (2, 0)  to 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bI9MwTaamhis",
      "metadata": {
        "id": "bI9MwTaamhis"
      },
      "outputs": [],
      "source": [
        "my_tensor = torch.zeros((5, 3)) # CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1d501aa1",
      "metadata": {
        "id": "1d501aa1"
      },
      "outputs": [],
      "source": [
        "# Modify the tensor to set element (0, 2) to 10 and element (2, 0) to 100\n",
        "my_tensor[0, 2] = 10\n",
        "my_tensor[2, 0] = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7QEV2uq-yqZK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QEV2uq-yqZK",
        "outputId": "5ddb156b-f12d-4adf-fea0-e6137b3cadce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "my_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "yAxzhRVGyr6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAxzhRVGyr6c",
        "outputId": "dab4d091-13d6-411c-c3de-481af4e354bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   0.,  10.],\n",
              "        [  0.,   0.,   0.],\n",
              "        [100.,   0.,   0.],\n",
              "        [  0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "my_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "FCM4GuyWylQV",
      "metadata": {
        "id": "FCM4GuyWylQV"
      },
      "outputs": [],
      "source": [
        "# Manually set the value at the first row and third column to 10,\n",
        "# and the value at the third row and first column to 100 in the tensor named \"my_tensor\".\n",
        "\n",
        "# CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZdEftwuPyyx9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdEftwuPyyx9",
        "outputId": "6f221a27-b622-44f4-9e4c-0891b4b5e8c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   0.,  10.],\n",
              "        [  0.,   0.,   0.],\n",
              "        [100.,   0.,   0.],\n",
              "        [  0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "my_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Eoa6rF80ZTa",
      "metadata": {
        "id": "6Eoa6rF80ZTa"
      },
      "source": [
        "# <font color = green>**Q2: Reshape tensor (1/2 Point)**\n",
        "You have following tensor as input:\n",
        "\n",
        "```x=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])```\n",
        "\n",
        "Using only reshaping functions (like view, reshape, transpose, permute), you need to get at the following tensor as output:\n",
        "\n",
        "```\n",
        "tensor([[ 0,  4,  8, 12, 16, 20],\n",
        "        [ 1,  5,  9, 13, 17, 21],\n",
        "        [ 2,  6, 10, 14, 18, 22],\n",
        "        [ 3,  7, 11, 15, 19, 23]])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "LDBQ6kYZ-JRV",
      "metadata": {
        "id": "LDBQ6kYZ-JRV"
      },
      "outputs": [],
      "source": [
        "x=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b6_SdFS-ke_x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6_SdFS-ke_x",
        "outputId": "4636e21d-d8d8-4c72-8396-5984507acd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19],\n",
            "        [20, 21, 22, 23]])\n"
          ]
        }
      ],
      "source": [
        "# Reshape the tensor into a 6x4 matrix\n",
        "x = x.view(6, 4)\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98af1dc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98af1dc0",
        "outputId": "4b1c80f5-68ea-4b9d-b352-f2b547f6a910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  4,  8, 12, 16, 20],\n",
            "        [ 1,  5,  9, 13, 17, 21],\n",
            "        [ 2,  6, 10, 14, 18, 22],\n",
            "        [ 3,  7, 11, 15, 19, 23]])\n"
          ]
        }
      ],
      "source": [
        "# Transpose the matrix\n",
        "x = x.t()\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dnw5qi7A4ysc",
      "metadata": {
        "id": "dnw5qi7A4ysc"
      },
      "source": [
        "# <font color = green>**Q3: Slice tensor (1Point)**\n",
        "\n",
        "- Slice the tensor x to get the following\n",
        ">- last row of x\n",
        ">- fourth column of x\n",
        ">- first three rows and first two columns - the shape of subtensor should be (3,2)\n",
        ">- odd valued rows and columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "STbUdF0J5IBD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STbUdF0J5IBD",
        "outputId": "ba05c6fc-2221-406b-a33f-49a34eb5b1ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  8, 10],\n",
              "        [11, 12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 8, 10], [11, 12, 13, 14, 15]])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "mgHPm0qP5ZU3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgHPm0qP5ZU3",
        "outputId": "18b3674e-98bb-4993-82e9-832932a03845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "hzQRs79A5JGd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQRs79A5JGd",
        "outputId": "60e87235-cdba-4d51-cde2-915d67490b5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Student Task: Retrieve the last row of the tensor 'x'\n",
        "# Hint: Negative indexing can help you select rows or columns counting from the end of the tensor.\n",
        "# Think about how you can select all columns for the desired row.\n",
        "last_row = x[-1, :] # CODE HERE\n",
        "last_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "-mb_Et866ZEW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mb_Et866ZEW",
        "outputId": "65f1107c-2379-4451-a0f1-cfd9b1ba2f51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4,  8, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Student Task: Retrieve the fourth column of the tensor 'x'\n",
        "# Hint: Pay attention to the indexing for both rows and columns.\n",
        "# Remember that indexing in Python starts from zero.\n",
        "fourth_column = x[:,3] # CODE HERE\n",
        "fourth_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c2VaG6Y16jsA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2VaG6Y16jsA",
        "outputId": "a58f818c-9bd8-4fb4-8766-300c1cad239d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2],\n",
              "        [ 6,  7],\n",
              "        [11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Student Task: Retrieve the first 3 rows and first 2 columns from the tensor 'x'.\n",
        "# Hint: Use slicing to extract the required subset of rows and columns.\n",
        "first_3_rows_2_columns = x[:3, :2]# CODE HERE\n",
        "first_3_rows_2_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "RHnSUpxs7O82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHnSUpxs7O82",
        "outputId": "5356c960-157b-42f3-e21d-831507f71fcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5],\n",
              "        [11, 13, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Student Task: Retrieve the rows and columns with odd-indexed positions from the tensor 'x'.\n",
        "# Hint: Use stride slicing to extract the required subset of rows and columns with odd indices.\n",
        "odd_valued_rows_columns = x[0::2, 0::2]# CODE HERE\n",
        "odd_valued_rows_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uSj20OEuf6bf",
      "metadata": {
        "id": "uSj20OEuf6bf"
      },
      "source": [
        "#  <font color = green>**Q4 -Normalize Function (1/2 Points)**<font>\n",
        "\n",
        "Write the function that normalizes the columns of a matrix. You have to compute the mean and standard deviation of each column. Then for each element of the column, you subtract the mean and divide by the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8L9JBFNilkWt",
      "metadata": {
        "id": "8L9JBFNilkWt"
      },
      "outputs": [],
      "source": [
        "# Given Data\n",
        "x = [[ 3,  60,  100, -100],\n",
        "     [ 2,  20,  600, -600],\n",
        "     [-5,  50,  900, -900]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "iRrhopVBl-0q",
      "metadata": {
        "id": "iRrhopVBl-0q"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch Tensor and set to float\n",
        "X = torch.tensor(x)\n",
        "X= X.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "S2MaocHxmEQJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2MaocHxmEQJ",
        "outputId": "5f1dcb12-2587-48c9-a5ff-d3a1c532ae1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Print shape and data type for verification\n",
        "print(X.shape)\n",
        "print(X.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "rPgb1L9RmQAU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPgb1L9RmQAU",
        "outputId": "870d6799-296b-49cd-eadf-41307dc7c11f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0.0000,   43.3333,  533.3333, -533.3333])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Compute and display the mean and standard deviation of each column for reference\n",
        "X.mean(axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-VFqgviWmME"
      },
      "id": "d-VFqgviWmME",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "qnM87Db1mqFH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnM87Db1mqFH",
        "outputId": "6e6bad25-61fd-42e8-8b8e-487e0bd16cf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  4.3589,  20.8167, 404.1452, 404.1452])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X.std(axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yy2hehDnJHOq",
      "metadata": {
        "id": "Yy2hehDnJHOq"
      },
      "source": [
        "- Your task starts here\n",
        "- Your normalize_matrix function should take a PyTorch tensor x as input.\n",
        "- It should return a tensor where the columns are normalized.\n",
        "- After implementing your function, use the code provided to verify if the mean for each column in Z is close to zero and the standard deviation is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "mwq8qnqFlu9V",
      "metadata": {
        "id": "mwq8qnqFlu9V"
      },
      "outputs": [],
      "source": [
        "def normalize_matrix(x):\n",
        "    # Calculate the mean along each column (axis 0)\n",
        "    mean = x.mean(dim=0)\n",
        "\n",
        "    # Calculate the standard deviation along each column (axis 0)\n",
        "    std = x.std(dim=0)\n",
        "\n",
        "    # Normalize each element in the columns by subtracting the mean and dividing by the standard deviation\n",
        "    y = (x - mean) / std\n",
        "\n",
        "    return y  # Return the normalized matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "m027Qcgwm9OL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m027Qcgwm9OL",
        "outputId": "296aa1bb-bee2-4b4e-a67a-85247655b884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6882,  0.8006, -1.0722,  1.0722],\n",
              "        [ 0.4588, -1.1209,  0.1650, -0.1650],\n",
              "        [-1.1471,  0.3203,  0.9073, -0.9073]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "Z = normalize_matrix(X)\n",
        "Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "78-0D3KfnHel",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78-0D3KfnHel",
        "outputId": "41c27338-b068-4e61-ffc8-81771fdb9e0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00,  4.9671e-08,  3.9736e-08, -3.9736e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "Z.mean(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z.std(axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3hgs8qQWsim",
        "outputId": "6fb0d3b3-e5c5-4481-8418-f8a13a40df88"
      },
      "id": "h3hgs8qQWsim",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc32848b",
      "metadata": {
        "id": "cc32848b"
      },
      "source": [
        "# <font color = 'green'>**Q5: In-place vs. Out-of-place Operations (1 Point)**\n",
        "\n",
        "1. Create a tensor `A` with values `[1, 2, 3]`.\n",
        "2. Perform an in-place addition (use `add_` method) of `5` to tensor `A`.\n",
        "3. Then, create another tensor `B` with values `[4, 5, 6]` and perform an out-of-place addition of `5`.\n",
        "\n",
        "**Print the memory addresses of `A` and `B` before and after the operations to demonstrate the difference in memory usage. Provide explanation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "19b3aaa5",
      "metadata": {
        "id": "19b3aaa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb6ece9-438b-48dc-a318-48012b23f335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original memory address of A: 132363084169600\n",
            "Memory address of A after in-place addition: 132363084169600\n",
            "A after in-place addition: tensor([6, 7, 8])\n",
            "Original memory address of B: 132363084169840\n",
            "Memory address of B after out-of-place addition: 132363084169760\n",
            "B after out-of-place addition: tensor([ 9, 10, 11])\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a tensor `A` with values [1, 2, 3]\n",
        "A = torch.tensor([1, 2, 3])\n",
        "print('Original memory address of A:', id(A))\n",
        "\n",
        "# Step 2: Perform in-place addition of 5 to tensor `A`\n",
        "A.add_(5)\n",
        "print('Memory address of A after in-place addition:', id(A))\n",
        "print('A after in-place addition:', A)\n",
        "\n",
        "# Step 3: Create a tensor `B` with values [4, 5, 6]\n",
        "B = torch.tensor([4, 5, 6])\n",
        "print('Original memory address of B:', id(B))\n",
        "\n",
        "# Step 4: Perform out-of-place addition of 5 to tensor `B`\n",
        "B = B + 5  # This creates a new tensor and assigns it to `B`\n",
        "print('Memory address of B after out-of-place addition:', id(B))\n",
        "print('B after out-of-place addition:', B)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aXi2TsYVElqy",
      "metadata": {
        "id": "aXi2TsYVElqy"
      },
      "source": [
        "**Provide Explanation for above question here :**\n",
        "\n",
        "### A. when you use in-place addition A.add_(5) , the operation changes the tensor A directly, therefore the memory address of A remains the same after the operation, as there is no need to create a new tensor\n",
        "\n",
        "### B. when you perform an out-of-place operation, like B+5, a new tensor is created and the memory address of 'B' changes after the operation. For this operation, a new tensor is created and the results are stored back to the original tensor B\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57bb1a4",
      "metadata": {
        "id": "f57bb1a4"
      },
      "source": [
        "# <font color = 'green'>**Q6: Tensor Broadcasting (1 Point)**\n",
        "\n",
        "1. Create two tensors `X` with shape `(3, 1)` and `Y` with shape `(1, 3)`. Perform an addition operation on `X` and `Y`.\n",
        "2. Explain how broadcasting is applied in this operation by describing the shape changes that occur internally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "699f9bd9",
      "metadata": {
        "id": "699f9bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed8e0db-2b63-426f-8bc9-20f173edf83d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: torch.Size([3, 1]) torch.Size([1, 3])\n",
            "Result: tensor([[5, 6, 7],\n",
            "        [6, 7, 8],\n",
            "        [7, 8, 9]])\n",
            "Result shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor X with shape (3, 1)\n",
        "X = torch.tensor([[1], [2], [3]])\n",
        "\n",
        "# Create tensor Y with shape (1, 3)\n",
        "Y = torch.tensor([[4, 5, 6]])\n",
        "\n",
        "# Print the original shapes\n",
        "print('Original shapes:', X.shape, Y.shape)\n",
        "\n",
        "# Perform the addition\n",
        "result = X + Y\n",
        "\n",
        "# Print the result and its shape\n",
        "print('Result:', result)\n",
        "print('Result shape:', result.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IblSVvPhE4-E",
      "metadata": {
        "id": "IblSVvPhE4-E"
      },
      "source": [
        "**Provide Explanation for above question here :**\n",
        "Initially, I created the tensors with different dimensions.\n",
        "Broadcasting allows for operations on tensors of different shapes by expanding one or both tensors to a compatible shape without copying data.\n",
        "In this case, X with shape (3, 1) was broadcasted to (3, 3) by repeating its single column across the other columns. Similarly, Y with shape (1, 3) was broadcasted to (3, 3) by repeating its single row across the other rows.\n",
        "The resulting tensor Z has a shape of (3, 3) and contains the element-wise sum of the broadcasted tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f2667e",
      "metadata": {
        "id": "e1f2667e"
      },
      "source": [
        "# <font color = 'green'>**Q7: Linear Algebra Operations (1 Point)**\n",
        "\n",
        "1. Create two matrices `M1` and `M2` of compatible shapes for matrix multiplication. Perform the multiplication and print the result.\n",
        "2. Then, create two vectors `V1` and `V2` and compute their dot product.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d45aed18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45aed18",
        "outputId": "43beef0d-6db1-4d55-b2bb-a8bf16ba7198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication result: tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "Dot product: tensor(32)\n"
          ]
        }
      ],
      "source": [
        "M1 = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "M2 = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "mat_multiplication = torch.mm(M1, M2)\n",
        "print('Matrix multiplication result:', mat_multiplication)\n",
        "\n",
        "# Step 2: Create two vectors V1 and V2\n",
        "V1 = torch.tensor([1, 2, 3])\n",
        "V2 = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Compute the dot product of V1 and V2\n",
        "dot_product = torch.dot(V1, V2)\n",
        "print('Dot product:', dot_product)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe24a961",
      "metadata": {
        "id": "fe24a961"
      },
      "source": [
        "# <font color = 'green'>**Q8: Manipulating Tensor Shapes (1 Point)**\n",
        "\n",
        "Given a tensor `T` with shape `(2, 3, 4)`, demonstrate how to\n",
        "1. reshape it to `(3, 8)` using view,\n",
        "2. reshape it to `(4, 2, 3` using reshape,\n",
        "3. transpose the first and last dimensions using permute.\n",
        "4. explain what is the difference between reshape and view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0644b861",
      "metadata": {
        "id": "0644b861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98def0eb-446b-42df-aff8-025960453003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T_view shape: torch.Size([3, 8])\n",
            "T_reshape shape: torch.Size([4, 2, 3])\n",
            "T_permute shape: torch.Size([4, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "T = torch.rand(2, 3, 4)\n",
        "\n",
        "# 1. Reshape using `view` to (3, 8)\n",
        "T_view = T.view(3, 8)\n",
        "print('T_view shape:', T_view.shape)\n",
        "\n",
        "# 2. Reshape using `reshape` to (4, 2, 3)\n",
        "T_reshape = T.reshape(4, 2, 3)\n",
        "print('T_reshape shape:', T_reshape.shape)\n",
        "\n",
        "# 3. Transpose the first and last dimensions using `permute`\n",
        "T_permute = T.permute(2, 1, 0)\n",
        "print('T_permute shape:', T_permute.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lb-861xsFXHN",
      "metadata": {
        "id": "Lb-861xsFXHN"
      },
      "source": [
        "**Provide Explanation for above question here :**\n",
        "\n",
        "view: Used to reshape the tensor T from (2, 3, 4) to (3, 8) by changing its shape without altering the underlying data layout.\n",
        "\n",
        "reshape: Reshaped the tensor T from (2, 3, 4) to (4, 2, 3) and handled the tensor's non-contiguous memory by creating a new tensor with the desired shape.\n",
        "\n",
        "permute: Reordered the dimensions of T from (2, 3, 4) to (4, 3, 2), changing the order of the dimensions without altering the tensor's data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5c7b62",
      "metadata": {
        "id": "1d5c7b62"
      },
      "source": [
        "# <font color = 'green'>**Q9: Tensor Concatenation and Stacking (1 Point)**\n",
        "\n",
        "Create tensors `C1` and `C2` both with shape (2, 3).\n",
        "1. Concatenate them along dimension 0 and then along dimension 1. Print the shape of the resulting tensor.\n",
        "2. Afterwards, stack the same tensors alomng dimension 0  and print the shape of the resulting tensor.\n",
        "3. What is the difference between stacking and concatinating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "69e2f7e0",
      "metadata": {
        "id": "69e2f7e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a03d32-55e7-4fd1-83a5-a31e01c48b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated along dimension 0: torch.Size([4, 3])\n",
            "Concatenated along dimension 1: torch.Size([2, 6])\n",
            "Stacked tensor shape: torch.Size([2, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Create tensors C1 and C2 with shape (2, 3)\n",
        "C1 = torch.rand(2, 3)\n",
        "C2 = torch.rand(2, 3)\n",
        "\n",
        "# 1. Concatenate along dimension 0\n",
        "concatenated_dim0 = torch.cat((C1, C2), dim=0)\n",
        "print('Concatenated along dimension 0:', concatenated_dim0.shape)\n",
        "\n",
        "# 2. Concatenate along dimension 1\n",
        "concatenated_dim1 = torch.cat((C1, C2), dim=1)\n",
        "print('Concatenated along dimension 1:', concatenated_dim1.shape)\n",
        "\n",
        "# 3. Stack along dimension 0\n",
        "stacked = torch.stack((C1, C2), dim=0)\n",
        "print('Stacked tensor shape:', stacked.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kmKpP5xBCCgt",
      "metadata": {
        "id": "kmKpP5xBCCgt"
      },
      "source": [
        "**Explain the diffrence between concatinating and stacking here**\n",
        "\n",
        "Concatenation along Dimension 0:\n",
        "torch.cat((C1, C2), dim=0)\n",
        "This combines C1 and C2 along the first dimension (rows), so the result is a single tensor with more rows but the same number of columns.\n",
        "Resulting Shape: (4, 3) — C1 and C2 are stacked on top of each other.\n",
        "\n",
        "Concatenation along Dimension 1:\n",
        "torch.cat((C1, C2), dim=1)\n",
        "This combines C1 and C2 along the second dimension (columns), so the result is a single tensor with more columns but the same number of rows.\n",
        "Resulting Shape: (2, 6) — C1 and C2 are placed side by side.\n",
        "\n",
        "\n",
        "Stacking along Dimension 0:\n",
        "torch.stack((C1, C2), dim=0)\n",
        "This creates a new dimension and stacks C1 and C2 along this new dimension. Each tensor becomes a separate \"slice\" along this new dimension.\n",
        "Resulting Shape: (2, 2, 3) — The new dimension (0) holds two layers (one for each of C1 and C2), each of shape (2, 3).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d0ed971",
      "metadata": {
        "id": "0d0ed971"
      },
      "source": [
        "# <font color = 'green'>**Q10: Advanced Indexing and Slicing (1 Point)**\n",
        "\n",
        "1. Given a tensor `D` with shape (6, 6), extract elements that are greater than 0.5.\n",
        "2. Then, extract the second and fourth rows from `D`.\n",
        "3. Finally, extract a sub-tensor from the top-left 3x3 block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "df969523",
      "metadata": {
        "id": "df969523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6afaae-31fe-44f9-a488-d241ebd9e5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements greater than 0.5:\n",
            " tensor([0.8292, 0.6681, 0.7118, 0.9073, 0.5648, 0.5332, 0.7644, 0.8222, 0.5956,\n",
            "        0.7425, 0.9295, 0.5248, 0.7486])\n",
            "\n",
            "Second and fourth rows:\n",
            " tensor([[0.0522, 0.4350, 0.1069, 0.5648, 0.1129, 0.1137],\n",
            "        [0.8222, 0.0661, 0.5956, 0.3014, 0.1175, 0.7425]])\n",
            "\n",
            "Top-left 3x3 block:\n",
            " tensor([[0.8292, 0.6681, 0.7118],\n",
            "        [0.0522, 0.4350, 0.1069],\n",
            "        [0.1725, 0.1402, 0.5332]])\n"
          ]
        }
      ],
      "source": [
        "D = torch.rand(6, 6)\n",
        "# 1. Extract elements greater than 0.5\n",
        "elements_greater_than_0_5 = D[D > 0.5]\n",
        "print('Elements greater than 0.5:\\n', elements_greater_than_0_5)\n",
        "\n",
        "# 2. Extract the second and fourth rows\n",
        "second_fourth_rows = D[[1, 3], :]\n",
        "print('\\nSecond and fourth rows:\\n', second_fourth_rows)\n",
        "\n",
        "# 3. Extract the top-left 3x3 block\n",
        "top_left_3x3 = D[:3, :3]\n",
        "print('\\nTop-left 3x3 block:\\n', top_left_3x3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c081cf3b",
      "metadata": {
        "id": "c081cf3b"
      },
      "source": [
        "# <font color = 'green'>**Q11: Tensor Mathematical Operations (1 Point)**\n",
        "\n",
        "1. Create a tensor `G` with values from 0 to π in steps of π/4.\n",
        "2. Compute and print the sine, cosine, and tangent logarithm and the exponential of `G`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4c22b354",
      "metadata": {
        "id": "4c22b354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cdc8a5-2182-4733-ca9b-23dfc50f1a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: tensor([0.0000, 0.7854, 1.5708, 2.3562, 3.1416])\n",
            "Sine of G: tensor([ 0.0000e+00,  7.0711e-01,  1.0000e+00,  7.0711e-01, -8.7423e-08])\n",
            "Cosine of G: tensor([ 1.0000e+00,  7.0711e-01, -4.3711e-08, -7.0711e-01, -1.0000e+00])\n",
            "Tangent of G: tensor([ 0.0000e+00,  1.0000e+00, -2.2877e+07, -1.0000e+00,  8.7423e-08])\n",
            "Natural logarithm of G: tensor([-0.2416,  0.4516,  0.8570,  1.1447])\n",
            "Exponential of G: tensor([ 1.0000,  2.1933,  4.8105, 10.5507, 23.1407])\n"
          ]
        }
      ],
      "source": [
        "G = torch.arange(0,torch.pi+torch.pi/4,step =torch.pi/4)\n",
        "print('G:', G)\n",
        "print('Sine of G:',  torch.sin(G))\n",
        "print('Cosine of G:',  torch.cos(G))\n",
        "print('Tangent of G:',  torch.tan(G))\n",
        "print('Natural logarithm of G:',  torch.log(G[1:]))\n",
        "print('Exponential of G:',  torch.exp(G))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629eb94b",
      "metadata": {
        "id": "629eb94b"
      },
      "source": [
        "# <font color = 'green'>Q12: **Tensor Reduction Operations (1 Point)**\n",
        "\n",
        "1. Create a 3x2 tensor `H`.\n",
        "2. Compute the sum of `H`. Print the result and shape after taking sun.\n",
        "3. Then, perform the same operations along dimension 0 and dimension 1, printing the results and shapes.\n",
        "4. What do you observe? How the shape changes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "729d7275",
      "metadata": {
        "id": "729d7275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3199921f-5e80-4921-b5d7-d44d43a709ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H: tensor([[0.4951, 0.3167],\n",
            "        [0.0548, 0.2115],\n",
            "        [0.1740, 0.8918]])\n",
            "\n",
            "Shape of original Tensor H: torch.Size([3, 2])\n",
            "\n",
            "Sum of H: tensor(2.1440)\n",
            "Shape after Sum of H: torch.Size([])\n",
            "\n",
            "Sum of H along dimension 0: tensor([0.7240, 1.4200])\n",
            "Shape after sum of H along dimension 0: torch.Size([2])\n",
            "\n",
            "Sum of H along dimension 1: tensor([0.8118, 0.2663, 1.0659])\n",
            "Shape after sum of H along dimension 1: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "# 1. Create a 3x2 tensor H\n",
        "H = torch.rand(3, 2)\n",
        "print('H:', H, end=\"\\n\\n\")\n",
        "print('Shape of original Tensor H:', H.shape, end=\"\\n\\n\")\n",
        "\n",
        "# 2. Compute the sum of H\n",
        "sum_H = torch.sum(H)\n",
        "print('Sum of H:', sum_H)\n",
        "print('Shape after Sum of H:', sum_H.shape, end=\"\\n\\n\")\n",
        "# 3. Compute the sum along dimension 0\n",
        "sum_H_dim0 = torch.sum(H, dim=0)\n",
        "print('Sum of H along dimension 0:', sum_H_dim0)\n",
        "print('Shape after sum of H along dimension 0:', sum_H_dim0.shape, end=\"\\n\\n\")\n",
        "\n",
        "# 4. Compute the sum along dimension 1\n",
        "sum_H_dim1 = torch.sum(H, dim=1)\n",
        "print('Sum of H along dimension 1:', sum_H_dim1)\n",
        "print('Shape after sum of H along dimension 1:', sum_H_dim1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hfmDz2OLb8M2",
      "metadata": {
        "id": "hfmDz2OLb8M2"
      },
      "source": [
        "**Provide your observations on shape changes here**\n",
        "\n",
        "In tensor reduction operations, summing all elements of a tensor results in a scalar with no dimensions, collapsing all axes into a single number. Summing along a specific dimension reduces that dimension while preserving others; for example, summing along dimension 0 of a 3x2 tensor results in a 1D tensor of shape (2,), representing the sum of each column, while summing along dimension 1 yields a 1D tensor of shape (3,), representing the sum of each row. Thus, summing across dimensions decreases the tensor's rank by collapsing the summed dimension while retaining the shape of the remaining dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a156a3a",
      "metadata": {
        "id": "4a156a3a"
      },
      "source": [
        "# <font color = 'green'>**Q13: Working with Tensor Data Types (1 Point)**\n",
        "\n",
        "1. Create a tensor `I` of data type float with values `[1.0, 2.0, 3.0]`.\n",
        "2. Convert `I` to data type int and print the result.\n",
        "3. Explain in which scenarios it's necessary to be cautious about the data type of tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "af427555",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af427555",
        "outputId": "5f973f74-03d0-46b0-9f7b-68679595c2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: tensor([1., 2., 3.])\n",
            "I converted to int: tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "# Solution for Q16\n",
        "I =  torch.tensor([1.0, 2.0, 3.0], dtype=torch.float) # CODE HERE\n",
        "print('I:', I)\n",
        "I_int = I.int()  #I.to(dtype=torch.int) # CODE HERE\n",
        "print('I converted to int:', I_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9yyx5WtweGNP",
      "metadata": {
        "id": "9yyx5WtweGNP"
      },
      "source": [
        "**Your explanations here**\n",
        "When working with tensor data types, it's crucial to be cautious about conversions between types due to potential precision loss and compatibility issues. Converting from float to int truncates decimal values, which can lead to a loss of precision that might affect numerical accuracy in computations.\n",
        "also, different data types also impact memory usage and performance, with smaller types potentially reducing memory consumption but possibly sacrificing precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2TU6l0nC3EfW",
      "metadata": {
        "id": "2TU6l0nC3EfW"
      },
      "source": [
        "# <font color = 'green'>**Q14. Speedtest for vectorization 1.5 Points** </font>\n",
        "\n",
        "Your goal is to measure the speed of linear algebra operations for different levels of vectorization.\n",
        "\n",
        "1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $1024 \\times 1024$.\n",
        "1. Compute $C = A B$ using matrix-matrix operations and report the time. (Hint: Use torch.mm)\n",
        "1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time. (hint use torch.mv inside a for loop)\n",
        "1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time. (Hint: use torch.dot inside nested for loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "wkKjtX0HH2wz",
      "metadata": {
        "id": "wkKjtX0HH2wz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "##Solution 1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# 1. Construct two matrices A and B with Gaussian random entries of size 1024x1024\n",
        "A = torch.randn(1024, 1024)\n",
        "B = torch.randn(1024, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "kSMH_j5OD2ZB",
      "metadata": {
        "id": "kSMH_j5OD2ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6fad7d-0288-4961-8b66-f5b013847cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by matrix: 0.07712960243225098 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "C = torch.mm(A, B)\n",
        "print(\"Matrix by matrix: \" + str(time.time() - start) + \" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "-tU8yGBP-Crk",
      "metadata": {
        "id": "-tU8yGBP-Crk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896b9ca2-bd4e-46d4-a7a3-8d25d6ecfe9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by vector: 0.2900547981262207 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 3\n",
        "C = torch.empty(1024, 1024)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(B.shape[1]):\n",
        "    C[:, i] = torch.mv(A, B[:, i])\n",
        "\n",
        "print(\"Matrix by vector: \" + str(time.time() - start) + \" seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "MFgJCFf6DUFK",
      "metadata": {
        "id": "MFgJCFf6DUFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e94482-ab41-4261-dbcc-e1baf35eb891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector by vector: 35.57971477508545 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 4\n",
        "C = torch.empty(1024, 1024)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(A.shape[0]):\n",
        "    for j in range(B.shape[1]):\n",
        "        C[i, j] = torch.dot(A[i, :], B[:, j])\n",
        "\n",
        "print(\"Vector by vector: \" + str(time.time() - start) + \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TtYsJM4mJNdE",
      "metadata": {
        "id": "TtYsJM4mJNdE"
      },
      "source": [
        "# <font color = 'green'>**Q15 : Redo Question 14 by using GPU - 1.5 Points**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fxJ1UlTf3Efb",
      "metadata": {
        "id": "fxJ1UlTf3Efb"
      },
      "source": [
        "<font size = 4, color = 'green'> **Using GPUs**\n",
        "\n",
        "How to use GPUs in Google Colab<br>\n",
        "In Google Colab -- Go to Runtime Tab at top -- select change runtime type -- for hardware accelartor choose GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_6ilpofMIe1e",
      "metadata": {
        "id": "_6ilpofMIe1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e845e5bf-be4c-4c4e-d123-3caa75fb20e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "# Check if GPU is availaible\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4XMhjifbJcu0",
      "metadata": {
        "id": "4XMhjifbJcu0"
      },
      "outputs": [],
      "source": [
        "## Solution 1\n",
        "torch.manual_seed(42)\n",
        "A= torch.randn((1024, 1024),device=device)\n",
        "B= torch.randn((1024, 1024),device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "pn-ZKI7sK9Oh",
      "metadata": {
        "id": "pn-ZKI7sK9Oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca090fd-9d0e-4deb-b2a3-f6f2ae6ec999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by matrix: 0.1557598114013672 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 2\n",
        "start=time.time()\n",
        "\n",
        "C =torch.mm(A, B) # code here\n",
        "\n",
        "print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "GcHPGEitLL8i",
      "metadata": {
        "id": "GcHPGEitLL8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8a51c5-ffed-45ed-a76d-56c76a109e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by vector: 0.15434908866882324 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 3\n",
        "C= torch.empty(1024,1024, device = device)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(B.shape[1]):\n",
        "    C[:, i] = torch.mv(A, B[:, i])# code here\n",
        "\n",
        "print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "wZ5LWSa2Lrdw",
      "metadata": {
        "id": "wZ5LWSa2Lrdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49e920d-116b-4450-e897-a9307738e6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector by vector: 57.57485508918762 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 4\n",
        "C= torch.empty(1024,1024, device = device)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(A.shape[0]):\n",
        "    for j in range(B.shape[1]):\n",
        "        C[i, j] = torch.dot(A[i, :], B[:, j])# code here\n",
        "\n",
        "print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experimenting with GPU and CPU options**"
      ],
      "metadata": {
        "id": "vzs2ANkHbYyX"
      },
      "id": "vzs2ANkHbYyX"
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "### Turning off GPU to show the time difference On CPU and that I was able to make the changes"
      ],
      "metadata": {
        "id": "Wz86W6NE-s-W"
      },
      "id": "Wz86W6NE-s-W",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edjGpIG5Z_AB"
      },
      "id": "edjGpIG5Z_AB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d511200-b24b-4d22-9c7d-b508b0f78b51",
        "id": "dSINYzC4aBML"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "# Check if GPU is availaible\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "id": "dSINYzC4aBML"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-4rMG6VMaBMM"
      },
      "outputs": [],
      "source": [
        "## Solution 1\n",
        "torch.manual_seed(42)\n",
        "A= torch.randn((1024, 1024),device=device)\n",
        "B= torch.randn((1024, 1024),device=device)"
      ],
      "id": "-4rMG6VMaBMM"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb6cddd-e433-4fc7-9259-1e52ac34cf9e",
        "id": "HsRtvQrgaBMN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by matrix: 0.40303468704223633 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 2\n",
        "start=time.time()\n",
        "\n",
        "C =torch.mm(A, B) # code here\n",
        "\n",
        "print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")"
      ],
      "id": "HsRtvQrgaBMN"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da17472-ae20-4600-a69e-37d3ae10c50d",
        "id": "ul2E9844aBMO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix by vector: 2.328982353210449 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 3\n",
        "C= torch.empty(1024,1024, device = device)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(B.shape[1]):\n",
        "    C[:, i] = torch.mv(A, B[:, i])# code here\n",
        "\n",
        "print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\")"
      ],
      "id": "ul2E9844aBMO"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35606ca-2b08-4c0b-bb2b-7a281653731f",
        "id": "xelpdou3aBMQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector by vector: 35.6391077041626 seconds\n"
          ]
        }
      ],
      "source": [
        "## Solution 4\n",
        "C= torch.empty(1024,1024, device = device)\n",
        "start = time.time()\n",
        "\n",
        "for i in range(A.shape[0]):\n",
        "    for j in range(B.shape[1]):\n",
        "        C[i, j] = torch.dot(A[i, :], B[:, j])# code here\n",
        "\n",
        "print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")"
      ],
      "id": "xelpdou3aBMQ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-w1UMxlmaOFd"
      },
      "id": "-w1UMxlmaOFd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}